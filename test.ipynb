{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['First', 'Name']\n"
     ]
    }
   ],
   "source": [
    "#将属性名按照标点，分割成token\n",
    "import re\n",
    "def snake_case_split(line):\n",
    "    #Python strip() 方法用于移除字符串头尾指定的字符（默认为空格或换行符）或字符序列。\n",
    "    #r表示非转义的原始字符串\n",
    "    #由于正则表达式通常都包含反斜杠，所以你最好使用原始字符串来表示它们。模式元素(如 r'\\t'，等价于 '\\\\t')匹配相应的特殊字符。\n",
    "    #[...]用来表示一组字符,单独列出：[amk] 匹配 'a'，'m'或'k'\n",
    "    line_split = re.split(r'[\\s_]',line.strip())\n",
    "    line_split = [line.strip() for line in line_split if len(line.strip())>0]\n",
    "    return line_split\n",
    "\n",
    "str = \"First_Name\"\n",
    "print(snake_case_split(str))\n",
    "\n",
    "\n",
    "#将属性按照大写字母，分割成token\n",
    "import re\n",
    "def camel_case_split(str):\n",
    "    if \"a\"<=str[0]<=\"z\" :\n",
    "        strTemp=str[0].upper()+str[1:]\n",
    "        return re.findall(r'[A-Z](?:[a-z]+|[A-Z]*(?=[A-Z]|$))', strTemp)\n",
    "    else :\n",
    "        return re.findall(r'[A-Z](?:[a-z]+|[A-Z]*(?=[A-Z]|$))', str)\n",
    "\n",
    "str = \"FirstName\"\n",
    "print(camel_case_split(str))\n",
    "\n",
    "\n",
    "#将属性名先按照snakeCase拆分，再按照camelCase拆分\n",
    "def attributeToToken(str):\n",
    "    tokenList1 = snake_case_split(str)\n",
    "    tokenList2 = []\n",
    "    for snakeToken in tokenList1:\n",
    "        camelTokenList = camel_case_split(snakeToken)\n",
    "        for token in camelTokenList:\n",
    "            tokenList2.append(token[0].lower()+token[1:])\n",
    "    return tokenList2\n",
    "\n",
    "str = \"FirstName_LastName\"\n",
    "list=attributeToToken(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载模型\n",
    "import fasttext\n",
    "fasttext.FastText.eprint = lambda x: None\n",
    "model = fasttext.load_model(\"/usr/dataLake/result/fil9.bin\")\n",
    "\n",
    "\n",
    "#将属性名的tokenList转换为词嵌入向量\n",
    "def tokenToVector(tokenList):\n",
    "    wordEmbedding=model.get_word_vector(tokenList[0])\n",
    "    length= len(tokenList)\n",
    "    for token in tokenList[1:]:\n",
    "        wordEmbedding=wordEmbedding+model.get_word_vector(token)\n",
    "    return wordEmbedding/length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.26734224,  0.15887718,  0.17169274, -0.4282757 , -0.18615206,\n",
       "       -0.13033642, -0.07404496,  0.07804422, -0.35618225, -0.12453329,\n",
       "       -0.08181277,  0.26787636, -0.07058604,  0.01830482,  0.11167918,\n",
       "       -0.31116903,  0.12473547,  0.21723196,  0.22184291,  0.03101896,\n",
       "        0.13705194, -0.05638621,  0.01378235,  0.03924557,  0.01057926,\n",
       "       -0.30158573,  0.23949865,  0.21460846,  0.06502027,  0.33148494,\n",
       "        0.08890073,  0.07159315,  0.22459815, -0.14856343, -0.04093441,\n",
       "        0.02196516, -0.02158085,  0.07680135,  0.08894321,  0.3914056 ,\n",
       "        0.38259572,  0.30266553,  0.15197313,  0.05165072,  0.04343948,\n",
       "       -0.5956884 , -0.01191438,  0.29723346,  0.00325351,  0.02289635,\n",
       "        0.02271349, -0.14330158,  0.11096019, -0.17221461,  0.26415366,\n",
       "        0.03461661, -0.1272608 , -0.04122745,  0.08267218, -0.09647307,\n",
       "        0.2005811 ,  0.22294575,  0.01480081, -0.11560582,  0.33165023,\n",
       "        0.20925225,  0.03384192, -0.05086027, -0.1735389 ,  0.02890766,\n",
       "       -0.0485907 ,  0.18262237,  0.00111851, -0.35112733,  0.16995646,\n",
       "       -0.08588757, -0.00821892, -0.07467809,  0.1060139 ,  0.13420777,\n",
       "        0.22623152, -0.48526466,  0.11540871,  0.16293977,  0.00793106,\n",
       "       -0.07024624,  0.06544884, -0.06824239, -0.4403869 , -0.11397684,\n",
       "        0.13215575,  0.25997782,  0.28954056, -0.33186197, -0.23790222,\n",
       "       -0.3812685 , -0.25888658,  0.17374843,  0.28411746, -0.20500344],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenList=[\"first\",\"name\"]\n",
    "w=tokenToVector(tokenList)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attribute:\n",
    "    def __init__(self, attributeName, originateFrom):\n",
    "        self.attributeName = attributeName\n",
    "        self.tokenList = attributeToToken(attributeName)\n",
    "        #属性的词嵌入表示\n",
    "        self.wordEmbedding = tokenToVector(self.tokenList)\n",
    "        #属性来自哪张表\n",
    "        self.originateFrom = originateFrom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Table:\n",
    "\n",
    "    def __init__(self, ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alightings', 'boardings', 'cross_street', 'location', 'routes']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/usr/dataLake/datasets/BenchmarkCsvfiles/CTA_Ridership_Avg_Weekday_Bus_Stop_Boardings_in_October_2012____c5_0____1.csv')\n",
    "\n",
    "#list函数返回一个表的所有属性，返回一个list\n",
    "print(list(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "#for循环中的info代表文件名\n",
    "attributeList = []\n",
    "for info in os.listdir('/usr/DataLake/datasets/BenchmarkCsvfiles'): \n",
    "    #去掉.csv后缀\n",
    "    tableName = info[0:-4]\n",
    "    domain = os.path.abspath('/usr/DataLake/datasets/BenchmarkCsvfiles') #获取文件夹的路径 \n",
    "    info = os.path.join(domain,info) #将路径与文件名结合起来就是每个文件的完整路径\n",
    "    df = pd.read_csv(info)   \n",
    "    for attributeName in list(df):\n",
    "        x=Attribute(attributeName, tableName)\n",
    "        #通过append函数将自定义类的对象放入list中\n",
    "        attributeList.append(x)\n",
    "        #print(attributeList[i])可证明是Attribute类的对象\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=0\n",
    "while a<20:\n",
    "    print(attributeList[a].attributeName)\n",
    "    print(attributeList[a].originateFrom)\n",
    "    a=a+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nt小，ITF大，权重大。\n",
    "#token越稀有，权重越大。\n",
    "#N是数据湖中有多少列。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
